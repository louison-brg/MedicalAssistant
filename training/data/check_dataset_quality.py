import numpy as np
import re
try:
    import matplotlib.pyplot as plt
    HAS_PLOT = True
except Exception:
    HAS_PLOT = False
from collections import Counter
from datasets import load_from_disk

# ==========================================================
# ğŸ” Analyse complÃ¨te du dataset avant fine-tuning
# ==========================================================

DATA_PATH = "training/data/processed_professor_phi3/tokenized"

print("ğŸ“¦ Chargement du dataset depuis :", DATA_PATH)
dataset = load_from_disk(DATA_PATH)
print(dataset)

# ==========================================================
# ğŸ§© Ã‰tape 1 â€” Structure du dataset
# ==========================================================
print("\nğŸ“‚ Colonnes disponibles :", dataset.column_names)

# Affiche un exemple brut
print("\nğŸ§  Exemple 0 :")
print(dataset[0])

# ==========================================================
# ğŸ§© Ã‰tape 2 â€” Longueur des sÃ©quences
# ==========================================================
if "input_ids" in dataset.column_names:
    lengths = [len(x) for x in dataset["input_ids"]]
    print("\nğŸ“ Analyse des longueurs de sÃ©quence (tokens) :")
    print(f"   - Nombre total dâ€™exemples : {len(lengths)}")
    print(f"   - Moyenne : {np.mean(lengths):.1f}")
    print(f"   - MÃ©diane : {np.median(lengths):.1f}")
    print(f"   - Maximum : {np.max(lengths)}")

    if HAS_PLOT:
        plt.hist(lengths, bins=50)
        plt.title("Distribution de la longueur des sÃ©quences")
        plt.xlabel("Nombre de tokens")
        plt.ylabel("FrÃ©quence")
        plt.show()
    else:
        print("â„¹ï¸ matplotlib non installÃ© â€” histogramme ignorÃ©.")
else:
    print("\nâš ï¸ Pas de colonne 'input_ids' â€” le dataset nâ€™est pas encore tokenisÃ©.")

empty = []

# ==========================================================
# ğŸ§© Ã‰tape 3 â€” DÃ©tection dâ€™exemples vides
# ==========================================================
if "input_ids" in dataset.column_names:
    empty = [i for i, ex in enumerate(dataset) if len(ex["input_ids"]) == 0]
    print(f"âš ï¸ Exemples vides : {len(empty)}")
    if len(empty) > 0:
        print("ğŸ‘‰ Conseil : supprimer avec dataset.filter(lambda ex: len(ex['input_ids']) > 0)")
else:
    if "text" in dataset.column_names:
        empty = [i for i, ex in enumerate(dataset) if not ex["text"].strip()]
        print(f"âš ï¸ Exemples textuels vides : {len(empty)}")

# ==========================================================
# ğŸ§© Ã‰tape 4 â€” RÃ©partition par type dâ€™exemple (si meta_info)
# ==========================================================
if "meta_info" in dataset.column_names:
    print("\nğŸ“Š RÃ©partition des types dâ€™exemples (meta_info) :")
    counts = Counter(dataset["meta_info"])
    for k, v in counts.items():
        print(f"   - {k}: {v}")
else:
    print("\nâ„¹ï¸ Aucune colonne 'meta_info' dÃ©tectÃ©e (pas de catÃ©gorisation des exemples).")

# ==========================================================
# ğŸ§© Ã‰tape 5 â€” VÃ©rification du format de prompt
# ==========================================================
def is_medical_prompt(text):
    return bool(re.search(r'(Patient|Question|Textbook|Doctor|Answer)', text))

if "text" in dataset.column_names:
    valid_ratio = sum(is_medical_prompt(t) for t in dataset["text"]) / len(dataset)
    print(f"\nâœ… {valid_ratio*100:.1f}% des exemples ont un format de prompt valide.")
    if valid_ratio < 0.8:
        print("âš ï¸ Peu dâ€™exemples contiennent un format clair (Patient:, Question:, etc.)")
else:
    print("\nâš ï¸ Impossible de vÃ©rifier les prompts â€” dataset dÃ©jÃ  tokenisÃ©.")

# ==========================================================
# ğŸ§© Ã‰tape 6 â€” VÃ©rification du vocabulaire mÃ©dical
# ==========================================================
medical_terms = ["heart", "lung", "infection", "tumor", "diabetes", "fever", "hypertension", "CT", "MRI"]
if "text" in dataset.column_names:
    ratio = sum(any(term in t.lower() for term in medical_terms) for t in dataset["text"]) / len(dataset)
    print(f"ğŸ©º {ratio*100:.1f}% des exemples contiennent du vocabulaire mÃ©dical.")
    if ratio < 0.4:
        print("âš ï¸ Le corpus semble peu mÃ©dical â€” attention Ã  la pertinence du fine-tuning.")
else:
    print("â„¹ï¸ Dataset tokenisÃ© â€” vocabulaire non vÃ©rifiable directement.")

# ==========================================================
# ğŸ§© Ã‰tape 7 â€” Rapport final
# ==========================================================
print("\n==================== ğŸ“‹ RAPPORT FINAL ====================")

if "input_ids" in dataset.column_names:
    print(f"ğŸ“ˆ Moyenne de longueur : {np.mean(lengths):.0f} tokens")
    print(f"ğŸ“‰ MÃ©diane : {np.median(lengths):.0f}")
    print(f"ğŸ“ Max : {np.max(lengths)}")
    if np.max(lengths) > 1024:
        print("âš ï¸ Certaines sÃ©quences dÃ©passent 1024 tokens (seront tronquÃ©es).")

if len(empty) > 0:
    print(f"âš ï¸ {len(empty)} exemples vides dÃ©tectÃ©s â†’ Ã  filtrer avant entraÃ®nement.")

if "meta_info" in dataset.column_names:
    print("ğŸ“Š Types dâ€™exemples prÃ©sents :", list(Counter(dataset["meta_info"]).keys()))

print("\nâœ… VÃ©rification terminÃ©e.")
